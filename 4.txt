import numpy as np

#Input array
X=np.array([[1,0,1,0],[1,0,1,1],[0,1,0,1]])

#Output
y=np.array([[1],[1],[0]])

#Sigmoid Function
def sigmoid (x):
    return 1/(1 + np.exp(-x))

#Derivative of Sigmoid Function
def derivatives_sigmoid(x):
    return x * (1 - x)

#Variable initialization
epoch=5000 #Setting training iterations
lr=0.1 #Setting learning rate
inputlayer_neurons = 4 #number of features in data set
hiddenlayer_neurons = 3 #number of hidden layers neurons
output_neurons = 1 #number of neurons at output layer

#weight and bias initialization
wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))
bh=np.random.uniform(size=(1,hiddenlayer_neurons))
wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))
bout=np.random.uniform(size=(1,output_neurons))

for i in range(epoch):
    #Forward Propogation
    hidden_layer_input1=np.dot(X,wh)
    hidden_layer_input=hidden_layer_input1 + bh
    hiddenlayer_activations = sigmoid(hidden_layer_input)
    
    output_layer_input1 = np.dot(hiddenlayer_activations,wout)
    output_layer_input = output_layer_input1+ bout
    output = sigmoid(output_layer_input)

    #Backpropagation
    #Compare the prediction with actual output 
    E = y-output
    #Calculate the slope/gradient of hidden and output neurons
    slope_output_layer = derivatives_sigmoid(output)
    slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)
    
    #compute the achange factor at output player
    d_output = E * slope_output_layer
    
    #In this step, the error will propoagate back into network which means at hidden layer.
    # For this, we will take the dot product of output layer delta with weight parameters of edges between hidden and output layer
    
    Error_at_hidden_layer = d_output.dot(wout.T)
    #Compute the change factor at hidden layer
    d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer
    
    #update the weights at output and hidden layer.
    wout += hiddenlayer_activations.T.dot(d_output) *lr
    wh += X.T.dot(d_hiddenlayer) *lr
    #update the bias at output and hidden layer.
    bout += np.sum(d_output, axis=0,keepdims=True) *lr
    bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr
    
print("Input:\n" + str(X))   
print("Actual output: \n" + str(y))
print("Predicted output:",output)
